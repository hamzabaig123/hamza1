import express from 'express';
import type { Request, Response } from 'express';
import dotenv from 'dotenv';
import OpenAI from 'Openai';
//import OpenRouter  from 'openai';
//import { openrouter } from '@openrouter/ai-sdk-provider';

dotenv.config();
console.log('Is OPENROUTER_API_KEY available?', !!process.env.OPENROUTER_API_KEY);
// Check if the key starts with 'sk-or'
console.log('Key prefix check:', process.env.OPENROUTER_API_KEY?.substring(0, 5));

const client = new OpenAI ({
   baseURL: 'https://api-inference.huggingface.co/models/facebook/bart-large-cnn',
   apiKey: process.env.HF_API_KEY,
});

const app = express();
app.use(express.json());
const port = process.env.PORT || 3000;

app.get('/', (req: Request, res: Response) => {
   res.send('Hello World!');
});

app.get('/api/hello',  (req: Request, res: Response) => {
   res.json({ message: 'Hello World!' });
});

app.post('/api/chat', async (req: Request,res: Response) => {
   const {prompt} = req.body;

   const response = await client.responses.create({
      model: 'facebook/bart-large-cnn',
      input:prompt,
      temperature: 0.2,
      max_output_tokens: 100,
    
   });

   res.json({message: response.output_text})
})

app.listen(port, () => {
   console.log(`Server is running on http://localhost:${port}`);
});
